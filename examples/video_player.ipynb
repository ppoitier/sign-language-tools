{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(dirname(\"../src/sign_language_tools\"))\n",
    "\n",
    "# Path of the dataset on my computer and ID of the video in this example\n",
    "DS_root = \"/media/hyperion/datasets/sign-languages/lsfb/lsfb-cont/\"\n",
    "video_id = \"CLSFBI0203A_S004_B\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing LSFB Dataset\n",
    "\n",
    "The LSFB dataset contains raw videos, MediaPipe Poses and gloss annotation for each hands of the signers. This example shows how to use the VideoPlayer to visualize all those information.\n",
    "\n",
    "If the dataset you are working with use pose from either MediaPipe or OpenPose, you can use the datatype created in the submodule `pose` of the `sign-language-tools` library to draw the edges between two point in the pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sign_language_tools.visualization.video.video_player import VideoPlayer\n",
    "\n",
    "# Loading the edges information for the hand and the hollistic pose of MediaPipe\n",
    "from sign_language_tools.pose.mediapipe.edges import UPPER_POSE_EDGES, HAND_EDGES\n",
    "\n",
    "player = VideoPlayer(root=DS_root, screenshot_dir=\"/home/jeromefink/Images\", fps=50)\n",
    "\n",
    "player.attach_video(f\"videos/{video_id}.mp4\")\n",
    "\n",
    "# Loading the pose from the LSFB files\n",
    "pose = np.load(f\"{DS_root}poses/pose/{video_id}.npy\")\n",
    "left_hand = np.load(f\"{DS_root}poses/left_hand/{video_id}.npy\")\n",
    "right_hand = np.load(f\"{DS_root}poses/right_hand/{video_id}.npy\")\n",
    "\n",
    "# Attaching the pose to the VideoPlayer\n",
    "player.attach_pose(\"Pose\", pose, connections=UPPER_POSE_EDGES)\n",
    "player.attach_pose(\"Left hand\", left_hand, connections=HAND_EDGES)\n",
    "player.attach_pose(\"Right hand\", right_hand, connections=HAND_EDGES)\n",
    "\n",
    "# Loading the annotations\n",
    "left_hand_annot = pd.read_csv(f\"{DS_root}annotations/csv/left/{video_id}.mp4.csv\")\n",
    "right_hand_annot = pd.read_csv(f\"{DS_root}annotations/csv/right/{video_id}.mp4.csv\")\n",
    "\n",
    "player.attach_segments(\"Left hand\", left_hand_annot)\n",
    "player.attach_segments(\"Right hand\", right_hand_annot)\n",
    "\n",
    "\n",
    "player.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
